{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinyl-bin/selenium/blob/main/good/bad-ing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD6yy6WKpOPa",
        "outputId": "2fec7559-2ef1-48e2-bd99-053b60862437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/24)\u001b[K\rremote: Counting objects:   8% (2/24)\u001b[K\rremote: Counting objects:  12% (3/24)\u001b[K\rremote: Counting objects:  16% (4/24)\u001b[K\rremote: Counting objects:  20% (5/24)\u001b[K\rremote: Counting objects:  25% (6/24)\u001b[K\rremote: Counting objects:  29% (7/24)\u001b[K\rremote: Counting objects:  33% (8/24)\u001b[K\rremote: Counting objects:  37% (9/24)\u001b[K\rremote: Counting objects:  41% (10/24)\u001b[K\rremote: Counting objects:  45% (11/24)\u001b[K\rremote: Counting objects:  50% (12/24)\u001b[K\rremote: Counting objects:  54% (13/24)\u001b[K\rremote: Counting objects:  58% (14/24)\u001b[K\rremote: Counting objects:  62% (15/24)\u001b[K\rremote: Counting objects:  66% (16/24)\u001b[K\rremote: Counting objects:  70% (17/24)\u001b[K\rremote: Counting objects:  75% (18/24)\u001b[K\rremote: Counting objects:  79% (19/24)\u001b[K\rremote: Counting objects:  83% (20/24)\u001b[K\rremote: Counting objects:  87% (21/24)\u001b[K\rremote: Counting objects:  91% (22/24)\u001b[K\rremote: Counting objects:  95% (23/24)\u001b[K\rremote: Counting objects: 100% (24/24)\u001b[K\rremote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects:   5% (1/20)\u001b[K\rremote: Compressing objects:  10% (2/20)\u001b[K\rremote: Compressing objects:  15% (3/20)\u001b[K\rremote: Compressing objects:  20% (4/20)\u001b[K\rremote: Compressing objects:  25% (5/20)\u001b[K\rremote: Compressing objects:  30% (6/20)\u001b[K\rremote: Compressing objects:  35% (7/20)\u001b[K\rremote: Compressing objects:  40% (8/20)\u001b[K\rremote: Compressing objects:  45% (9/20)\u001b[K\rremote: Compressing objects:  50% (10/20)\u001b[K\rremote: Compressing objects:  55% (11/20)\u001b[K\rremote: Compressing objects:  60% (12/20)\u001b[K\rremote: Compressing objects:  65% (13/20)\u001b[K\rremote: Compressing objects:  70% (14/20)\u001b[K\rremote: Compressing objects:  75% (15/20)\u001b[K\rremote: Compressing objects:  80% (16/20)\u001b[K\rremote: Compressing objects:  85% (17/20)\u001b[K\rremote: Compressing objects:  90% (18/20)\u001b[K\rremote: Compressing objects:  95% (19/20)\u001b[K\rremote: Compressing objects: 100% (20/20)\u001b[K\rremote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "Receiving objects:   0% (1/115)   \rReceiving objects:   1% (2/115)   \rReceiving objects:   2% (3/115)   \rReceiving objects:   3% (4/115)   \rReceiving objects:   4% (5/115)   \rReceiving objects:   5% (6/115)   \rReceiving objects:   6% (7/115)   \rReceiving objects:   7% (9/115)   \rReceiving objects:   8% (10/115)   \rReceiving objects:   9% (11/115)   \rReceiving objects:  10% (12/115)   \rReceiving objects:  11% (13/115)   \rReceiving objects:  12% (14/115)   \rReceiving objects:  13% (15/115)   \rReceiving objects:  14% (17/115)   \rReceiving objects:  15% (18/115)   \rReceiving objects:  16% (19/115)   \rReceiving objects:  17% (20/115)   \rReceiving objects:  18% (21/115)   \rReceiving objects:  19% (22/115)   \rReceiving objects:  20% (23/115)   \rReceiving objects:  21% (25/115)   \rReceiving objects:  22% (26/115)   \rReceiving objects:  23% (27/115)   \rReceiving objects:  24% (28/115)   \rReceiving objects:  25% (29/115)   \rReceiving objects:  26% (30/115)   \rReceiving objects:  27% (32/115)   \rReceiving objects:  28% (33/115)   \rReceiving objects:  29% (34/115)   \rReceiving objects:  30% (35/115)   \rReceiving objects:  31% (36/115)   \rReceiving objects:  32% (37/115)   \rReceiving objects:  33% (38/115)   \rReceiving objects:  34% (40/115)   \rReceiving objects:  35% (41/115)   \rReceiving objects:  36% (42/115)   \rReceiving objects:  37% (43/115)   \rremote: Total 115 (delta 11), reused 10 (delta 3), pack-reused 91\u001b[K\n",
            "Receiving objects:  38% (44/115)   \rReceiving objects:  39% (45/115)   \rReceiving objects:  40% (46/115)   \rReceiving objects:  41% (48/115)   \rReceiving objects:  42% (49/115)   \rReceiving objects:  43% (50/115)   \rReceiving objects:  44% (51/115)   \rReceiving objects:  45% (52/115)   \rReceiving objects:  46% (53/115)   \rReceiving objects:  47% (55/115)   \rReceiving objects:  48% (56/115)   \rReceiving objects:  49% (57/115)   \rReceiving objects:  50% (58/115)   \rReceiving objects:  51% (59/115)   \rReceiving objects:  52% (60/115)   \rReceiving objects:  53% (61/115)   \rReceiving objects:  54% (63/115)   \rReceiving objects:  55% (64/115)   \rReceiving objects:  56% (65/115)   \rReceiving objects:  57% (66/115)   \rReceiving objects:  58% (67/115)   \rReceiving objects:  59% (68/115)   \rReceiving objects:  60% (69/115)   \rReceiving objects:  61% (71/115)   \rReceiving objects:  62% (72/115)   \rReceiving objects:  63% (73/115)   \rReceiving objects:  64% (74/115)   \rReceiving objects:  65% (75/115)   \rReceiving objects:  66% (76/115)   \rReceiving objects:  67% (78/115)   \rReceiving objects:  68% (79/115)   \rReceiving objects:  69% (80/115)   \rReceiving objects:  70% (81/115)   \rReceiving objects:  71% (82/115)   \rReceiving objects:  72% (83/115)   \rReceiving objects:  73% (84/115)   \rReceiving objects:  74% (86/115)   \rReceiving objects:  75% (87/115)   \rReceiving objects:  76% (88/115)   \rReceiving objects:  77% (89/115)   \rReceiving objects:  78% (90/115)   \rReceiving objects:  79% (91/115)   \rReceiving objects:  80% (92/115)   \rReceiving objects:  81% (94/115)   \rReceiving objects:  82% (95/115)   \rReceiving objects:  83% (96/115)   \rReceiving objects:  84% (97/115)   \rReceiving objects:  85% (98/115)   \rReceiving objects:  86% (99/115)   \rReceiving objects:  87% (101/115)   \rReceiving objects:  88% (102/115)   \rReceiving objects:  89% (103/115)   \rReceiving objects:  90% (104/115)   \rReceiving objects:  91% (105/115)   \rReceiving objects:  92% (106/115)   \rReceiving objects:  93% (107/115)   \rReceiving objects:  94% (109/115)   \rReceiving objects:  95% (110/115)   \rReceiving objects:  96% (111/115)   \rReceiving objects:  97% (112/115)   \rReceiving objects:  98% (113/115)   \rReceiving objects:  99% (114/115)   \rReceiving objects: 100% (115/115)   \rReceiving objects: 100% (115/115), 1.27 MiB | 28.28 MiB/s, done.\n",
            "Resolving deltas:   0% (0/50)   \rResolving deltas:   6% (3/50)   \rResolving deltas:  10% (5/50)   \rResolving deltas:  12% (6/50)   \rResolving deltas:  14% (7/50)   \rResolving deltas:  18% (9/50)   \rResolving deltas:  22% (11/50)   \rResolving deltas:  40% (20/50)   \rResolving deltas:  66% (33/50)   \rResolving deltas:  70% (35/50)   \rResolving deltas:  78% (39/50)   \rResolving deltas:  92% (46/50)   \rResolving deltas:  96% (48/50)   \rResolving deltas: 100% (50/50)   \rResolving deltas: 100% (50/50), done.\n",
            "/content/Mecab-ko-for-Google-Colab/Mecab-ko-for-Google-Colab/Mecab-ko-for-Google-Colab/Mecab-ko-for-Google-Colab/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2022-07-02 15:05:05--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::6b17:d1f5, 2406:da00:ff00::22cd:e0db, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNAZI2YCUN&Expires=1656775777&x-amz-security-token=FwoGZXIvYXdzEEgaDE75hP9xIxC%2FCVQM0yK%2BAYL7OIQAcohs3GqA4doAmRE2uvvgbrTmyOnxT2VU2dRiTTUfyPGVKRbKmcBTnfbl0g6BXK1%2FL0pufwKeiiFvFX2fJsrXy3rvjg2RjXzuAefsjW%2Bkg61KQXYB1%2FIz81g3NxXZDq2i9pcpsio%2BfnGh3BEbht5PuAMlUrWVHbEj8VAhbMZwrRyEPzWH3XqR0nP9hjvY9aI4lm%2FrFSvMkCT9qrF8az4ngAdsH6KHbyGwCztn6oJGQTqO4JNtGUptQFwo2bqBlgYyLbdSpgwqbwqkIs0ZCbNwbqsTqM1nqtgAPq5PjidYbxtBtF3zL2Y5RD8N0o4Caw%3D%3D&Signature=hQFz56qCMbl6BtBvYKd3m2wvA7Q%3D [following]\n",
            "--2022-07-02 15:05:05--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNAZI2YCUN&Expires=1656775777&x-amz-security-token=FwoGZXIvYXdzEEgaDE75hP9xIxC%2FCVQM0yK%2BAYL7OIQAcohs3GqA4doAmRE2uvvgbrTmyOnxT2VU2dRiTTUfyPGVKRbKmcBTnfbl0g6BXK1%2FL0pufwKeiiFvFX2fJsrXy3rvjg2RjXzuAefsjW%2Bkg61KQXYB1%2FIz81g3NxXZDq2i9pcpsio%2BfnGh3BEbht5PuAMlUrWVHbEj8VAhbMZwrRyEPzWH3XqR0nP9hjvY9aI4lm%2FrFSvMkCT9qrF8az4ngAdsH6KHbyGwCztn6oJGQTqO4JNtGUptQFwo2bqBlgYyLbdSpgwqbwqkIs0ZCbNwbqsTqM1nqtgAPq5PjidYbxtBtF3zL2Y5RD8N0o4Caw%3D%3D&Signature=hQFz56qCMbl6BtBvYKd3m2wvA7Q%3D\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.234.65\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.234.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz.4’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-07-02 15:05:05 (28.5 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz.4’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2022-07-02 15:05:19--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c5:2ef4, 2406:da00:ff00::6b17:d1f5, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNEKKDFX5C&Expires=1656776074&x-amz-security-token=FwoGZXIvYXdzEEkaDN%2Fpm7uDaUkANxgrWiK%2BAUbkVyHgvp2M7pacLFrUyuN4WGA6delcPjV3y9Cu7KPp838TSW2m%2FTMkS1cWPqL%2FRelewrpUmzjIBQozM4f%2FY3KPGTQa05RsAXH1CrZY1NxybY17zBNOk4VatOHODAF1GbMjFdtlE3ca3p6Vw%2BXZkEvgh2Dm5O6dJD74%2F2TM9cuY%2B1NB25BRgbd6SvPzWqj5BBuF%2FjNW0CCmoWhhpa5gJsiwsjPv2PC2GLypQKcWllm%2FJWvOOGQN7H31xXY4asMogr2BlgYyLXcuPmgcbiUe1QqyCDUCJXJgqP5G3QEnJhT0%2BTr1U%2BOhmXbM%2BlCrhQgOD1yn3Q%3D%3D&Signature=OU5%2FbiwhuRMtkcbvc7z%2Be4x5ZqA%3D [following]\n",
            "--2022-07-02 15:05:19--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNEKKDFX5C&Expires=1656776074&x-amz-security-token=FwoGZXIvYXdzEEkaDN%2Fpm7uDaUkANxgrWiK%2BAUbkVyHgvp2M7pacLFrUyuN4WGA6delcPjV3y9Cu7KPp838TSW2m%2FTMkS1cWPqL%2FRelewrpUmzjIBQozM4f%2FY3KPGTQa05RsAXH1CrZY1NxybY17zBNOk4VatOHODAF1GbMjFdtlE3ca3p6Vw%2BXZkEvgh2Dm5O6dJD74%2F2TM9cuY%2B1NB25BRgbd6SvPzWqj5BBuF%2FjNW0CCmoWhhpa5gJsiwsjPv2PC2GLypQKcWllm%2FJWvOOGQN7H31xXY4asMogr2BlgYyLXcuPmgcbiUe1QqyCDUCJXJgqP5G3QEnJhT0%2BTr1U%2BOhmXbM%2BlCrhQgOD1yn3Q%3D%3D&Signature=OU5%2FbiwhuRMtkcbvc7z%2Be4x5ZqA%3D\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.28.220\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.28.220|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz.4’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  94.8MB/s    in 0.5s    \n",
            "\n",
            "2022-07-02 15:05:20 (94.8 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz.4’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXctcIxapSu0"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from collections import Counter\n",
        "from konlpy.tag import Mecab\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu5IEK-epVo7"
      },
      "outputs": [],
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/naver_shopping.txt\", filename=\"ratings_total.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6Two9dZpYWD"
      },
      "outputs": [],
      "source": [
        "total_data = pd.read_table('ratings_total.txt', names=['ratings', 'reviews'])\n",
        "print('전체 리뷰 개수 :',len(total_data)) # 전체 리뷰 개수 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68pjkqJ51bhf"
      },
      "outputs": [],
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/vinyl-bin/selenium/main/naverfor_average.csv\", filename=\"ratings_for.csv\")\n",
        "df = pd.read_csv(\"ratings_for.csv\", error_bad_lines=False)\n",
        "total_rating = df['star'].sum() # 판다스 구문으로 cost열을 불러 들이고 sum함수로 값을 더한다.\n",
        "average_rating = round(total_rating / df['star'].count(), 2) # 평균은 count함수로 총합을 나눈다.\n",
        "#data = {'filename': [filename2], 'sum': [total_rating], 'average': [average_rating]}\n",
        "#all_dataFrame.append(pd.DataFrame(data=data)) # data파일을 데이터 프레임으로 만들고 리스트에 저장한다.\n",
        "\n",
        "average_rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrzFl9xfpapu"
      },
      "outputs": [],
      "source": [
        "total_data[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUjpv1tB0ZqO"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gDOXCNWpc3b"
      },
      "outputs": [],
      "source": [
        "total_data['label'] = np.select([total_data.ratings > 3], [1], default=0)\n",
        "total_data[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hndDXZFCpfXQ"
      },
      "outputs": [],
      "source": [
        "total_data['ratings'].nunique(), total_data['reviews'].nunique(), total_data['label'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J8fPJYDpiG5"
      },
      "outputs": [],
      "source": [
        "total_data.drop_duplicates(subset=['reviews'], inplace=True) # reviews 열에서 중복인 내용이 있다면 중복 제거\n",
        "print('총 샘플의 수 :',len(total_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXFntLTRpkB2"
      },
      "outputs": [],
      "source": [
        "print(total_data.isnull().values.any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwKy-JFUpn0p"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = train_test_split(total_data, test_size = 0.25, random_state = 42)\n",
        "print('훈련용 리뷰의 개수 :', len(train_data))\n",
        "print('테스트용 리뷰의 개수 :', len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bwS6OPqpqZ0"
      },
      "outputs": [],
      "source": [
        "train_data['label'].value_counts().plot(kind = 'bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9sb8LhmptQA"
      },
      "outputs": [],
      "source": [
        "print(train_data.groupby('label').size().reset_index(name = 'count'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlEXOqLmpwYo"
      },
      "outputs": [],
      "source": [
        "# 한글과 공백을 제외하고 모두 제거\n",
        "train_data['reviews'] = train_data['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "train_data['reviews'].replace('', np.nan, inplace=True)\n",
        "print(train_data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67XWepJzpy7w"
      },
      "outputs": [],
      "source": [
        "test_data.drop_duplicates(subset = ['reviews'], inplace=True) # 중복 제거\n",
        "test_data['reviews'] = test_data['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
        "test_data['reviews'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n",
        "test_data = test_data.dropna(how='any') # Null 값 제거\n",
        "print('전처리 후 테스트용 샘플의 개수 :',len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ps6lhdESp1xT"
      },
      "outputs": [],
      "source": [
        "mecab = Mecab()\n",
        "print(mecab.morphs('와 이런 것도 상품이라고 차라리 내가 만드는 게 나을 뻔'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJj5rjO4p6E8"
      },
      "outputs": [],
      "source": [
        "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4YMS_y5p8Vo"
      },
      "outputs": [],
      "source": [
        "train_data['tokenized'] = train_data['reviews'].apply(mecab.morphs)\n",
        "train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kOxNpKFp-X-"
      },
      "outputs": [],
      "source": [
        "test_data['tokenized'] = test_data['reviews'].apply(mecab.morphs)\n",
        "test_data['tokenized'] = test_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2S4M2PSqBC3"
      },
      "outputs": [],
      "source": [
        "negative_words = np.hstack(train_data[train_data.label == 0]['tokenized'].values)\n",
        "positive_words = np.hstack(train_data[train_data.label == 1]['tokenized'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sidirQ8qEk0"
      },
      "outputs": [],
      "source": [
        "negative_word_count = Counter(negative_words)\n",
        "print(negative_word_count.most_common(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xP6FwDHhqIn4"
      },
      "outputs": [],
      "source": [
        "positive_word_count = Counter(positive_words)\n",
        "print(positive_word_count.most_common(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGYlwqNnqLXD"
      },
      "outputs": [],
      "source": [
        "fig,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n",
        "text_len = train_data[train_data['label']==1]['tokenized'].map(lambda x: len(x))\n",
        "ax1.hist(text_len, color='red')\n",
        "ax1.set_title('Positive Reviews')\n",
        "ax1.set_xlabel('length of samples')\n",
        "ax1.set_ylabel('number of samples')\n",
        "print('긍정 리뷰의 평균 길이 :', np.mean(text_len))\n",
        "\n",
        "text_len = train_data[train_data['label']==0]['tokenized'].map(lambda x: len(x))\n",
        "ax2.hist(text_len, color='blue')\n",
        "ax2.set_title('Negative Reviews')\n",
        "fig.suptitle('Words in texts')\n",
        "ax2.set_xlabel('length of samples')\n",
        "ax2.set_ylabel('number of samples')\n",
        "print('부정 리뷰의 평균 길이 :', np.mean(text_len))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xjRZqn-qOb6"
      },
      "outputs": [],
      "source": [
        "X_train = train_data['tokenized'].values\n",
        "y_train = train_data['label'].values\n",
        "X_test= test_data['tokenized'].values\n",
        "y_test = test_data['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vzPTPyrqQj2"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADgxZv28qTdn"
      },
      "outputs": [],
      "source": [
        "threshold = 2\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W94Xr2qAqWzh"
      },
      "outputs": [],
      "source": [
        "vocab_size = total_cnt - rare_cnt + 2\n",
        "print('단어 집합의 크기 :',vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yr6Bmah2qZGP"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(vocab_size, oov_token = 'OOV') \n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_VPrth4qbiY"
      },
      "outputs": [],
      "source": [
        "print(X_train[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pItjeyJvqd8u"
      },
      "outputs": [],
      "source": [
        "print(X_test[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzmzNbtYqjFx"
      },
      "outputs": [],
      "source": [
        "print('리뷰의 최대 길이 :',max(len(review) for review in X_train))\n",
        "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
        "plt.hist([len(review) for review in X_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJh0qaUeqk7T"
      },
      "outputs": [],
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  count = 0\n",
        "  for sentence in nested_list:\n",
        "    if(len(sentence) <= max_len):\n",
        "        count = count + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZkz0LQaqoKe"
      },
      "outputs": [],
      "source": [
        "max_len = 80\n",
        "below_threshold_len(max_len, X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nc33nuMq6Qo"
      },
      "outputs": [],
      "source": [
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CJdU57Tq9ZG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, Dropout, Activation, LSTM, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "embedding_dim = 100\n",
        "hidden_units = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv1D(64, 5, padding='valid', activation='relu', strides=1))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "# model.add(LSTM(250,return_sequences=True))\n",
        "# model.add(LSTM(250,return_sequences=True))\n",
        "# model.add(LSTM(250,return_sequences=True))\n",
        "# model.add(LSTM(250,return_sequences=True))\n",
        "model.add(LSTM(250,return_sequences=True))\n",
        "model.add(LSTM(250,return_sequences=True))\n",
        "model.add(LSTM(250))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl1qQ5D2YKlU"
      },
      "outputs": [],
      "source": [
        "loaded_model = load_model('best_model.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncLkHsp0pe-L"
      },
      "outputs": [],
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "  new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
        "  new_sentence = mecab.morphs(new_sentence)\n",
        "  new_sentence = [word for word in new_sentence if not word in stopwords]\n",
        "  encoded = tokenizer.texts_to_sequences([new_sentence])\n",
        "  pad_new = pad_sequences(encoded, maxlen = max_len)\n",
        "\n",
        "  score = float(loaded_model.predict(pad_new))\n",
        "  if(score > 0.5):\n",
        "    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\".format(score * 100))\n",
        "  else:\n",
        "    print(\"{:.2f}% 확률로 부정 리뷰입니다.\".format((1 - score) * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRRG-Yo-pf15"
      },
      "outputs": [],
      "source": [
        "sentiment_predict(\"기대 엄청 하고 구매했는데 역류하고 방울도 별로네요……조카한테 선물해줬는데 실망입니다\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "  new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
        "  new_sentence = mecab.morphs(new_sentence)\n",
        "  new_sentence = [word for word in new_sentence if not word in stopwords]\n",
        "  encoded = tokenizer.texts_to_sequences([new_sentence])\n",
        "  pad_new = pad_sequences(encoded, maxlen = max_len)\n",
        "\n",
        "  score = float(loaded_model.predict(pad_new))\n",
        "  if(score > 0.5):\n",
        "  \n",
        "    return score * 100\n",
        "  else:\n",
        "  \n",
        "    return score * 100"
      ],
      "metadata": {
        "id": "fAch6-NLUOmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "with codecs.open('/content/finalsenti1.txt', 'r', encoding='utf-8', errors='ignore') as f:\n",
        "    content = f.readlines()\n",
        "\n",
        "# content = [line.rstrip('\\n') for line in content]\n",
        "    \n",
        "print(content)"
      ],
      "metadata": {
        "id": "oE2Cp0c7VjAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = content\n",
        "for i in test:\n",
        "  if (sentiment_predict(str(i)) > 50):\n",
        "    print(i, sep='\\n')"
      ],
      "metadata": {
        "id": "_u_Tnhm6YUGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "test = content\n",
        "for i in test:\n",
        "  if (sentiment_predict(str(i)) > 50):\n",
        "    data = {print(i)}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv('good.csv', index=False)\n"
      ],
      "metadata": {
        "id": "Ug62-lsC3k44"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "senticopy_LSTM.ipynb의 사본",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}